{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTSmIgVIRqzPkpT3H7QnRq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomeipau/streamlit-example/blob/master/Fake_Jobs_Deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "wgKMgddDF8pK",
        "outputId": "67df8b92-8907-40e8-a2a0-0c3b88a339f5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'texthero'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-255667f940fc>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjsonify\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrender_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtexthero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'texthero'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from flask import Flask,request,jsonify,render_template\n",
        "import texthero\n",
        "import nltk\n",
        "from nltk import stem\n",
        "from nltk import tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import texthero as hero\n",
        "import re\n",
        "\n",
        "app = Flask(__name__)\n",
        "tfidf = pickle.load(open('./content/tf_idf.pkl','rb'))\n",
        "model = pickle.load(open('./content/final_model.pkl','rb'))\n",
        "column_entities = pickle.load(open('./content/column_entities.pkl','rb'))\n",
        "\n",
        "\n",
        "w_tokenizer = tokenize.WhitespaceTokenizer()\n",
        "stemmer = stem.SnowballStemmer(\"english\")\n",
        "def stemming(text):\n",
        "    '''\n",
        "    input  : text\n",
        "    output :  lemmazitzed text\n",
        "    '''\n",
        "    return ' '.join([stemmer.stem(word) for word in w_tokenizer.tokenize(text)])\n",
        "\n",
        "def remove_long_texts(text):\n",
        "    words = [word for word in text.split() if len(word)<21]\n",
        "    return ' '.join(words)\n",
        "\n",
        "def remove_digits(text):\n",
        "    return re.sub(r'[\\d\\|]', '', text)\n",
        "\n",
        "def clean(text):\n",
        "    s = pd.Series([text])\n",
        "    text = s.pipe(hero.clean)[0]\n",
        "    text = remove_long_texts(text)\n",
        "    text = remove_digits(text)\n",
        "    text = stemming(text)\n",
        "    return tfidf.transform([text]).toarray()[0]\n",
        "\n",
        "\n",
        "def employment_list(param):\n",
        "    employments = column_entities[0]\n",
        "    arr = np.zeros((1,len(employments)),dtype=int).tolist()[0]\n",
        "    index = employments.index(param)\n",
        "    if index is not None:\n",
        "        arr[index] = 1\n",
        "        return arr\n",
        "    else:\n",
        "        return arr\n",
        "\n",
        "def experience_list(param):\n",
        "    arr = [0,0,0,0,0,0,0,0]\n",
        "    experiences = column_entities[1]\n",
        "    arr = np.zeros((1,len(experiences)),dtype=int).tolist()[0]\n",
        "    index = experiences.index(param)\n",
        "    if index is not None:\n",
        "        arr[index] = 1\n",
        "        return arr\n",
        "    else:\n",
        "        return arr\n",
        "\n",
        "def edu_list(param):\n",
        "    educations = column_entities[2]\n",
        "    arr = np.zeros((1,len(educations)),dtype=int).tolist()[0]\n",
        "    index = educations.index(param)\n",
        "    if index is not None:\n",
        "        arr[index] = 1\n",
        "        return arr\n",
        "    else:\n",
        "        return arr\n",
        "\n",
        "def industry_list(param):\n",
        "    industries = column_entities[3]\n",
        "    arr = np.zeros((1,len(industries)),dtype=int).tolist()[0]\n",
        "    index = industries.index(param)\n",
        "    if index is not None:\n",
        "        arr[index] = 1\n",
        "        return arr\n",
        "    else:\n",
        "        return arr\n",
        "\n",
        "def function_list(param):\n",
        "    functions = column_entities[4]\n",
        "    arr = np.zeros((1,len(functions)),dtype=int).tolist()[0]\n",
        "    index = functions.index(param)\n",
        "    if index is not None:\n",
        "        arr[index] = 1\n",
        "        return arr\n",
        "    else:\n",
        "        return arr\n",
        "\n",
        "def preaper_data(clean_desc,required_experience,employment_type,has_questions\n",
        "            ,company_logo,telecommuting,required_education,industry,function):\n",
        "\n",
        "    result = []\n",
        "    result = result + [int(telecommuting)]\n",
        "    result = result + [int(company_logo)]\n",
        "    result = result + [int(has_questions)]\n",
        "    result = result + edu_list(required_education)\n",
        "    result = result + employment_list(employment_type)\n",
        "    result = result + experience_list(required_experience)\n",
        "    result = result +  industry_list(industry)\n",
        "    result = result + function_list(function)\n",
        "    result = result + list(clean_desc)\n",
        "    return pd.Series(result)\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html',prediction=None)\n",
        "\n",
        "@app.route('/predict',methods = ['POST'])\n",
        "def predict():\n",
        "    if request.method == 'POST':\n",
        "        title = request.form['title']\n",
        "        description = request.form['description']\n",
        "        requirment = request.form['requirment']\n",
        "        required_experience = request.form['required_experience']\n",
        "        employment_type = request.form['employment_type']\n",
        "        has_questions = request.form['has_questions']\n",
        "        company_logo = request.form['company_logo']\n",
        "        telecommuting = request.form['telecommuting']\n",
        "        required_education = request.form['required_education']\n",
        "        industry = request.form['industry']\n",
        "        function = request.form['function']\n",
        "        desc = title + description+requirment\n",
        "        clean_desc = clean(desc)\n",
        "\n",
        "        if len(set(clean_desc)) == 1:\n",
        "            predict = [1]\n",
        "        else:\n",
        "            data = preaper_data(clean_desc,required_experience,employment_type,has_questions\n",
        "                ,company_logo,telecommuting,required_education,industry,function)\n",
        "            predict = model.predict(data.values.reshape(1,-1))\n",
        "        return render_template('result.html',prediction = predict)\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    app.run(debug=True)"
      ]
    }
  ]
}